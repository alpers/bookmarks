# RESEARCH

- CS & General
    - 


- Information Retrieval
    - Attention Is All You Need https://arxiv.org/abs/1706.03762
    - BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models https://arxiv.org/abs/2104.08663
    - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding https://arxiv.org/abs/1810.04805
    - Semantic Retrieval Models https://github.com/caiyinqiong/Semantic-Retrieval-Models
    - Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks https://arxiv.org/abs/1908.10084
    - The Probabilistic Relevance Framework: BM25 and Beyond http://dx.doi.org/10.1561/1500000019
    - Xception: Deep Learning with Depthwise Separable Convolutions https://arxiv.org/abs/1610.02357


- Image Retrieval
    - A Survey of Visual Transformers https://arxiv.org/abs/2111.06091
    - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale https://arxiv.org/abs/2010.11929
    - How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers https://arxiv.org/abs/2106.10270
    - Image Understanding and the Web: a State-of-the-Art Review https://arxiv.org/abs/2005.02127
    - Learning Transferable Visual Models From Natural Language Supervision https://arxiv.org/abs/2103.00020 / https://github.com/openai/CLIP
    - Vision Transformer and MLP-Mixer Architectures https://github.com/google-research/vision_transformer
    - Vision Transformer for Small-Size Datasets https://arxiv.org/abs/2112.13492
    - When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations https://arxiv.org/abs/2106.01548

